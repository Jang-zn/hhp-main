# Kafka 설정 및 운영 가이드

## 📚 목차
1. [Kafka 기본 개념](#kafka-기본-개념)
2. [KRaft 모드 vs ZooKeeper 모드](#kraft-모드-vs-zookeeper-모드)
3. [로컬 개발환경 설정](#로컬-개발환경-설정)
4. [Spring Boot Kafka 설정](#spring-boot-kafka-설정)
5. [일반적인 에러 케이스 및 해결방안](#일반적인-에러-케이스-및-해결방안)
6. [성능 튜닝 및 모니터링](#성능-튜닝-및-모니터링)
7. [운영 환경 고려사항](#운영-환경-고려사항)

---

## Kafka 기본 개념

### 핵심 구성요소
- **Broker**: 메시지를 저장하고 전달하는 Kafka 서버
- **Topic**: 메시지가 분류되는 카테고리
- **Partition**: Topic을 분할한 단위, 병렬 처리와 확장성 제공
- **Producer**: 메시지를 Topic에 발행하는 클라이언트
- **Consumer**: Topic에서 메시지를 구독하는 클라이언트
- **Consumer Group**: 동일한 Topic을 분담해서 처리하는 Consumer들의 그룹

### 메시지 순서 보장
```
Topic: user-events (3 partitions)
┌─ Partition 0: user:1 → user:1 → user:1  (순서 보장)
├─ Partition 1: user:2 → user:2 → user:2  (순서 보장)  
└─ Partition 2: user:3 → user:3 → user:3  (순서 보장)

같은 파티션 내에서만 순서가 보장됨!
```

---

## KRaft 모드 vs ZooKeeper 모드

### KRaft 모드 (Kafka 2.8+, 3.0+에서 안정화)

**장점:**
- ZooKeeper 의존성 제거로 아키텍처 단순화
- 더 빠른 메타데이터 처리
- 메타데이터 파티션을 통한 확장성 개선
- 운영 복잡도 감소

**단점:**
- 상대적으로 새로운 기술 (운영 경험 부족)
- 일부 기능이 아직 완전하지 않을 수 있음

### ZooKeeper 모드 (전통적 방식)

**장점:**
- 검증된 안정성
- 풍부한 운영 경험과 문서
- 모든 기능 지원

**단점:**
- ZooKeeper 클러스터 별도 관리 필요
- 메타데이터 처리 성능 제한
- 아키텍처 복잡도 증가

### 선택 기준
```
KRaft 권장: 새로운 프로젝트, 단순한 아키텍처 선호
ZooKeeper 권장: 기존 운영 중인 시스템, 안정성 최우선
```

---

## 로컬 개발환경 설정

### 1. Kafka 다운로드 및 설치

```bash
# 1. Kafka 다운로드 (2.13-3.6.1 버전 예시)
wget https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz
tar -xzf kafka_2.13-3.6.1.tgz
cd kafka_2.13-3.6.1

# 2. 환경변수 설정 (선택사항)
export KAFKA_HOME=/path/to/kafka_2.13-3.6.1
export PATH=$PATH:$KAFKA_HOME/bin
```

### 2. KRaft 모드로 Kafka 실행

```bash
# 1. 클러스터 UUID 생성
KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"

# 2. 로그 디렉토리 포맷
bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties

# 3. Kafka 서버 시작
bin/kafka-server-start.sh config/kraft/server.properties
```

### 3. Docker Compose를 이용한 설정

```yaml
# docker-compose.yml
version: '3.8'
services:
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
```

### 4. 기본 테스트

```bash
# 1. 토픽 생성
bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

# 2. 메시지 발행
echo "Hello Kafka" | bin/kafka-console-producer.sh --topic test-topic --bootstrap-server localhost:9092

# 3. 메시지 소비
bin/kafka-console-consumer.sh --topic test-topic --from-beginning --bootstrap-server localhost:9092
```

---

## Spring Boot Kafka 설정

### 1. 의존성 추가

```kotlin
// build.gradle.kts
dependencies {
    // Kafka
    implementation("org.springframework.kafka:spring-kafka")
    testImplementation("org.springframework.kafka:spring-kafka-test")
    testImplementation("org.testcontainers:kafka") // 테스트용
}
```

### 2. 설정 파일 (application.yml)

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    
    # Producer 설정
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: all                    # 모든 복제본에서 확인
      retries: 3                   # 재시도 횟수
      batch-size: 16384           # 배치 크기 (16KB)
      linger-ms: 1                # 배치 대기 시간
      buffer-memory: 33554432     # 총 메모리 (32MB)
      properties:
        enable.idempotence: true  # 멱등성 보장
        max.in.flight.requests.per.connection: 5
    
    # Consumer 설정
    consumer:
      group-id: my-service
      auto-offset-reset: earliest  # 처음부터 읽기
      enable-auto-commit: false   # 수동 커밋
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "com.example.events"
        max.poll.records: 500       # 한 번에 가져올 최대 레코드 수
        max.poll.interval.ms: 300000 # 최대 폴링 간격 (5분)
        session.timeout.ms: 10000    # 세션 타임아웃 (10초)
        heartbeat.interval.ms: 3000  # 하트비트 간격 (3초)
```

### 3. Configuration 클래스

```java
@Configuration
@EnableKafka
public class KafkaConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    // Producer 설정
    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        
        // 성능 및 안정성 설정
        configProps.put(ProducerConfig.ACKS_CONFIG, "all");
        configProps.put(ProducerConfig.RETRIES_CONFIG, 3);
        configProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
        
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    // Consumer 설정
    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "my-service");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        
        // JSON 역직렬화 설정
        props.put(JsonDeserializer.TRUSTED_PACKAGES, "com.example.events");
        
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = 
            new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        
        // 수동 ACK 설정
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE);
        
        // 에러 핸들링
        factory.setCommonErrorHandler(new DefaultErrorHandler(
            (record, exception) -> {
                log.error("Kafka 메시지 처리 실패: {}", record, exception);
            }
        ));
        
        return factory;
    }
}
```

### 4. Producer 사용 예시

```java
@Service
public class EventPublisher {
    
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    public void publishEvent(String topic, String key, Object event) {
        CompletableFuture<SendResult<String, Object>> future = 
            kafkaTemplate.send(topic, key, event);
            
        future.whenComplete((result, ex) -> {
            if (ex == null) {
                log.info("메시지 전송 성공: topic={}, partition={}, offset={}", 
                        topic, result.getRecordMetadata().partition(), 
                        result.getRecordMetadata().offset());
            } else {
                log.error("메시지 전송 실패: topic={}", topic, ex);
            }
        });
    }
}
```

### 5. Consumer 사용 예시

```java
@Service
public class EventConsumer {
    
    @KafkaListener(topics = "user-events", groupId = "user-service")
    public void handleUserEvent(
            ConsumerRecord<String, UserEvent> record,
            Acknowledgment ack) {
        try {
            UserEvent event = record.value();
            log.info("사용자 이벤트 수신: {}", event);
            
            // 비즈니스 로직 처리
            processUserEvent(event);
            
            // 수동 커밋
            ack.acknowledge();
            
        } catch (Exception e) {
            log.error("사용자 이벤트 처리 실패: {}", record.value(), e);
            // 에러 처리 로직 (재시도, DLQ 전송 등)
        }
    }
}
```

---

## 일반적인 에러 케이스 및 해결방안

### 1. 연결 관련 에러

#### Error: Connection refused

```bash
# 에러 메시지
org.apache.kafka.common.errors.TimeoutException: 
Failed to update metadata after 60000 ms.
```

**원인:**
- Kafka 서버가 실행되지 않음
- 잘못된 bootstrap-servers 설정
- 방화벽 또는 네트워크 문제

**해결방안:**
```bash
# 1. Kafka 서버 상태 확인
ps aux | grep kafka

# 2. 포트 확인
netstat -tlnp | grep :9092

# 3. 연결 테스트
telnet localhost 9092

# 4. 설정 파일 확인
cat config/server.properties | grep listeners
```

#### Error: DNS Resolution

```bash
# 에러 메시지
java.net.UnknownHostException: kafka
```

**해결방안:**
```yaml
# Docker 환경에서 localhost로 변경
spring:
  kafka:
    bootstrap-servers: localhost:9092  # kafka -> localhost
```

### 2. 직렬화/역직렬화 에러

#### Error: Deserialization failed

```bash
# 에러 메시지
org.apache.kafka.common.errors.SerializationException: 
Error deserializing key/value for partition topic-0 at offset 1
```

**원인:**
- Producer와 Consumer의 Serializer/Deserializer 불일치
- JSON 스키마 변경
- 신뢰할 수 없는 패키지

**해결방안:**
```java
// 1. JSON 신뢰 패키지 설정
props.put(JsonDeserializer.TRUSTED_PACKAGES, "*"); // 모든 패키지 허용 (개발용)
props.put(JsonDeserializer.TRUSTED_PACKAGES, "com.example.events"); // 특정 패키지만

// 2. 타입 정보 포함
props.put(JsonDeserializer.VALUE_DEFAULT_TYPE, "com.example.events.BaseEvent");

// 3. 스키마 호환성을 위한 @JsonIgnoreProperties 사용
@JsonIgnoreProperties(ignoreUnknown = true)
public class UserEvent {
    // 필드들
}
```

### 3. 메모리 및 성능 에러

#### Error: OutOfMemoryError

```bash
# 에러 메시지
java.lang.OutOfMemoryError: Java heap space
```

**원인:**
- 배치 크기가 너무 큼
- 너무 많은 미처리 메시지 누적
- Consumer가 느려서 백프레셔 발생

**해결방안:**
```java
// Producer 설정 조정
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 8192);      // 16384 -> 8192
props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 16777216); // 32MB -> 16MB
props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 1);

// Consumer 설정 조정
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 100);    // 500 -> 100
props.put(ConsumerConfig.FETCH_MAX_BYTES_CONFIG, 1048576); // 1MB

// JVM 힙 크기 증가
java -Xmx2G -Xms1G -jar app.jar
```

#### Error: Consumer lag

**원인:**
- Consumer 처리 속도가 Producer보다 느림
- 파티션 수 부족
- Consumer 인스턴스 수 부족

**해결방안:**
```bash
# 1. Consumer 그룹 상태 확인
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-group --describe

# 2. 파티션 증가
bin/kafka-topics.sh --alter --topic my-topic --partitions 6 --bootstrap-server localhost:9092

# 3. Consumer 인스턴스 증가
@KafkaListener(topics = "my-topic", concurrency = "3")
```

### 4. 오프셋 관리 에러

#### Error: Offset out of range

```bash
# 에러 메시지
org.apache.kafka.clients.consumer.OffsetOutOfRangeException: 
Fetch position 1000 is out of range
```

**원인:**
- 오프셋이 삭제됨 (retention 설정)
- 잘못된 오프셋 커밋

**해결방안:**
```java
// 1. auto-offset-reset 설정
props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest"); // 또는 "latest"

// 2. 수동 오프셋 리셋
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group my-group --topic my-topic --reset-offsets --to-earliest --execute
```

### 5. 트랜잭션 에러

#### Error: Transaction timeout

```bash
# 에러 메시지
org.apache.kafka.common.errors.TimeoutException: 
Timeout of 60000ms expired before successfully committing the transaction
```

**해결방안:**
```java
// Producer 트랜잭션 설정 조정
props.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, 30000); // 30초
props.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, 30000);

// Broker 설정 조정 (server.properties)
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
```

---

## 성능 튜닝 및 모니터링

### 1. Producer 성능 튜닝

```java
// 처리량 최적화
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 32768);        // 32KB
props.put(ProducerConfig.LINGER_MS_CONFIG, 10);            // 10ms 대기
props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy"); // 압축

// 지연시간 최적화
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 0);            // 배치 비활성화
props.put(ProducerConfig.LINGER_MS_CONFIG, 0);             // 즉시 전송
props.put(ProducerConfig.ACKS_CONFIG, "1");                // 리더만 확인
```

### 2. Consumer 성능 튜닝

```java
// 처리량 최적화
props.put(ConsumerConfig.FETCH_MIN_BYTES_CONFIG, 50000);      // 50KB
props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 500);      // 500ms 대기
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 1000);      // 1000개

// 동시 처리
@KafkaListener(topics = "my-topic", concurrency = "10")
```

### 3. 모니터링 메트릭

```yaml
# JMX 메트릭 활성화
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  metrics:
    export:
      prometheus:
        enabled: true
```

**주요 메트릭:**
- Producer: `kafka.producer.record-send-rate`
- Consumer: `kafka.consumer.records-consumed-rate`  
- Consumer Lag: `kafka.consumer.lag`

### 4. 로그 설정

```xml
<!-- logback-spring.xml -->
<configuration>
    <logger name="org.apache.kafka" level="WARN"/>
    <logger name="org.springframework.kafka" level="INFO"/>
    <logger name="kafka.coordinator" level="INFO"/>
</configuration>
```

---

## 운영 환경 고려사항

### 1. 보안 설정

```properties
# server.properties
listeners=SASL_PLAINTEXT://localhost:9092
security.inter.broker.protocol=SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=PLAIN
sasl.enabled.mechanisms=PLAIN
```

### 2. 백업 및 복구

```bash
# 1. 토픽 설정 백업
bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --describe

# 2. 오프셋 백업
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --all-groups --describe

# 3. MirrorMaker를 이용한 클러스터 복제
bin/kafka-mirror-maker.sh --consumer.config source-consumer.properties \
  --producer.config target-producer.properties --whitelist=".*"
```

### 3. 클러스터 확장

```bash
# 1. 새 브로커 추가 후 파티션 재분산
bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
  --reassignment-json-file reassignment.json --execute

# 2. 파티션 증가 (주의: 키 기반 파티셔닝에 영향)
bin/kafka-topics.sh --alter --topic my-topic --partitions 10 \
  --bootstrap-server localhost:9092
```

### 4. 용량 계획

```bash
# 메시지 크기와 처리량 기반 계산
일일 메시지 수: 1,000,000
평균 메시지 크기: 1KB  
보관 기간: 7일
복제 계수: 3

필요 용량 = 1,000,000 × 1KB × 7일 × 3 = 21GB
```

---

## 마무리

이 가이드는 Kafka의 기본 개념부터 운영 환경까지의 전반적인 내용을 다룹니다. 각 환경과 요구사항에 맞게 설정을 조정하고, 충분한 테스트를 통해 안정성을 확보하시기 바랍니다.

**추가 학습 자료:**
- [Apache Kafka 공식 문서](https://kafka.apache.org/documentation/)
- [Confluent Platform 문서](https://docs.confluent.io/)
- [Spring Kafka 문서](https://spring.io/projects/spring-kafka)